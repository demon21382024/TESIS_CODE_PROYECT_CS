{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20898b3",
   "metadata": {},
   "source": [
    "# Carga, configuraci√≥n e inicio de proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2984d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd96409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 3e-4\n",
    "TEMPERATURE = 0.07\n",
    "\n",
    "# Configuraci√≥n SSL\n",
    "USE_SUBSET = True\n",
    "SUBSET_SUBJECTS = 30\n",
    "SUBSET_CONDITIONS = ['nm-01', 'nm-02', 'nm-03', 'nm-04']\n",
    "SUBSET_ANGLES = ['090', '180']\n",
    "SUBSET_FRAMES_PER_SEQ = 15\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608168e",
   "metadata": {},
   "source": [
    "# SSL Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d919c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CASIAB_SSL(Dataset):\n",
    "    \"\"\"\n",
    "    Data structure: subject_id/condition(bg-01,nm-01,...)/angle(000,018,...)/frames\n",
    "    \"\"\"\n",
    "    def __init__(self, root_path, use_subset=True, subset_subjects=10, subset_conditions=None, subset_angles=None, frames_per_seq=15):\n",
    "        self.root = Path(root_path)\n",
    "        self.images = []\n",
    "        \n",
    "        # Obtener sujetos\n",
    "        all_subjects = sorted([d for d in self.root.iterdir() if d.is_dir()])\n",
    "        subjects = all_subjects[:subset_subjects] if use_subset else all_subjects\n",
    "        \n",
    "        print(f\"\\nDataset desde: {root_path}\")\n",
    "        print(f\"Sujetos: {len(subjects)}/{len(all_subjects)}\")\n",
    "        if subset_conditions:\n",
    "            print(f\"Condiciones: {subset_conditions}\")\n",
    "        if subset_angles:\n",
    "            print(f\"√Ångulos: {subset_angles}\")\n",
    "        \n",
    "        total_sequences = 0\n",
    "        for subject_dir in subjects:\n",
    "            for condition_dir in subject_dir.iterdir():\n",
    "                if not condition_dir.is_dir():\n",
    "                    continue\n",
    "                \n",
    "                # Filtrar condiciones\n",
    "                if subset_conditions and condition_dir.name not in subset_conditions:\n",
    "                    continue\n",
    "                    \n",
    "                for angle_dir in condition_dir.iterdir():\n",
    "                    if not angle_dir.is_dir():\n",
    "                        continue\n",
    "                    \n",
    "                    # Filtrar √°ngulos \n",
    "                    if subset_angles and angle_dir.name not in subset_angles:\n",
    "                        continue\n",
    "                    \n",
    "                    total_sequences += 1\n",
    "                    frames = sorted([f for f in angle_dir.iterdir() if f.suffix.lower() in ['.png', '.jpg', '.bmp']])\n",
    "                    \n",
    "                    # Muestreo uniforme de frames\n",
    "                    if len(frames) > frames_per_seq:\n",
    "                        step = len(frames) / frames_per_seq\n",
    "                        frames = [frames[int(i * step)] for i in range(frames_per_seq)]\n",
    "                    \n",
    "                    self.images.extend(frames)\n",
    "        \n",
    "        print(f\"Secuencias: {total_sequences}\")\n",
    "        print(f\"Total frames: {len(self.images)}\")\n",
    "        \n",
    "        # Transformaciones\n",
    "        self.base_transform = transforms.Compose([\n",
    "            transforms.Resize(IMG_SIZE, antialias=True),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        self.ssl_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(IMG_SIZE, scale=(0.5, 1.0), antialias=True),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))], p=0.3),\n",
    "        ])\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.images[idx]).convert(\"L\")\n",
    "        img = self.base_transform(img)\n",
    "        \n",
    "        view1 = self.ssl_transform(img)\n",
    "        view2 = self.ssl_transform(img)\n",
    "        \n",
    "        return view1, view2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76b9afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaitBackbone(nn.Module):\n",
    "    def __init__(self, embed_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Projection head for SimCLR\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, embed_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.projection(x)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        return z\n",
    "\n",
    "class NTXentLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    NT-Xent Loss (SimCLR).\n",
    "    \"\"\"\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "    \n",
    "    def forward(self, z1, z2):\n",
    "        batch_size = z1.size(0)\n",
    "        \n",
    "        # Forzar float32 para evitar overflow en mixed precision\n",
    "        z1 = z1.float()\n",
    "        z2 = z2.float()\n",
    "        \n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        sim_matrix = torch.mm(z, z.t()) / self.temperature\n",
    "        mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n",
    "        sim_matrix.masked_fill_(mask, -1e9)  # Reducido para evitar overflow\n",
    "        \n",
    "        labels = torch.cat([\n",
    "            torch.arange(batch_size, 2 * batch_size),\n",
    "            torch.arange(0, batch_size)\n",
    "        ]).to(z.device)\n",
    "        \n",
    "        loss = self.criterion(sim_matrix, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc119e91",
   "metadata": {},
   "source": [
    "## Execute SSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf0312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ssl(root_path, save_path=\"backbone_ssl_best.pth\"):\n",
    "    dataset = CASIAB_SSL(\n",
    "        root_path=root_path,\n",
    "        use_subset=USE_SUBSET,\n",
    "        subset_subjects=SUBSET_SUBJECTS,\n",
    "        subset_conditions=SUBSET_CONDITIONS,\n",
    "        subset_angles=SUBSET_ANGLES,\n",
    "        frames_per_seq=SUBSET_FRAMES_PER_SEQ\n",
    "    )\n",
    "    \n",
    "    # No add multiprocessing (Windows)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True if DEVICE == \"cuda\" else False,\n",
    "    )\n",
    "    \n",
    "    # Modelo\n",
    "    model = GaitBackbone(embed_dim=256).to(DEVICE)\n",
    "    criterion = NTXentLoss(temperature=TEMPERATURE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "    \n",
    "    # GradScaler para mixed precision (desactivado por defecto para estabilidad)\n",
    "    USE_MIXED_PRECISION = False  # Cambiar a True si no hay problemas de overflow\n",
    "    scaler = GradScaler('cuda') if (DEVICE == \"cuda\" and USE_MIXED_PRECISION) else None\n",
    "    \n",
    "    print(f\"\\nConfiguraci√≥n:\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Epochs: {EPOCHS}\")\n",
    "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"Steps/epoch: {len(loader)}\")\n",
    "    print(f\"Total steps: {EPOCHS * len(loader)}\\n\")\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, (view1, view2) in enumerate(loader):\n",
    "            view1 = view1.to(DEVICE, non_blocking=True)\n",
    "            view2 = view2.to(DEVICE, non_blocking=True)\n",
    "            \n",
    "            if scaler:\n",
    "                with autocast('cuda'):\n",
    "                    z1 = model(view1)\n",
    "                    z2 = model(view2)\n",
    "                    loss = criterion(z1, z2)\n",
    "                \n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                z1 = model(view1)\n",
    "                z2 = model(view2)\n",
    "                loss = criterion(z1, z2)\n",
    "                \n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_epoch_loss = epoch_loss / len(loader)\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch:2d}/{EPOCHS} | Loss: {avg_epoch_loss:.4f} | \"\n",
    "              f\"Time: {epoch_time:.1f}s | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        \n",
    "        if avg_epoch_loss < best_loss:\n",
    "            best_loss = avg_epoch_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, save_path)\n",
    "    \n",
    "    print(f\"Entrenamiento finalizado\")\n",
    "    print(f\"Mejor loss: {best_loss:.4f}\")\n",
    "    print(f\"Modelo guardado: {save_path}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0541de83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset desde: C:/Users/JuanTF/Desktop/Gait_Recognition/archive/output\n",
      "Sujetos: 30/124\n",
      "Condiciones: ['nm-01', 'nm-02', 'nm-03', 'nm-04']\n",
      "√Ångulos: ['090', '180']\n",
      "Secuencias: 240\n",
      "Total frames: 3581\n",
      "\n",
      "Configuraci√≥n:\n",
      "Batch size: 64\n",
      "Epochs: 10\n",
      "Learning rate: 0.0003\n",
      "Steps/epoch: 56\n",
      "Total steps: 560\n",
      "\n",
      "Epoch  1/10 | Loss: 3.7324 | Time: 47.7s | LR: 0.000293\n",
      "Epoch  2/10 | Loss: 2.6707 | Time: 9.4s | LR: 0.000271\n",
      "Epoch  3/10 | Loss: 2.1379 | Time: 9.1s | LR: 0.000238\n",
      "Epoch  4/10 | Loss: 1.8254 | Time: 9.1s | LR: 0.000197\n",
      "Epoch  5/10 | Loss: 1.5906 | Time: 9.3s | LR: 0.000150\n",
      "Epoch  6/10 | Loss: 1.4274 | Time: 9.4s | LR: 0.000104\n",
      "Epoch  7/10 | Loss: 1.3103 | Time: 9.3s | LR: 0.000063\n",
      "Epoch  8/10 | Loss: 1.2302 | Time: 9.4s | LR: 0.000030\n",
      "Epoch  9/10 | Loss: 1.1376 | Time: 9.4s | LR: 0.000008\n",
      "Epoch 10/10 | Loss: 1.0919 | Time: 9.3s | LR: 0.000001\n",
      "Entrenamiento finalizado\n",
      "Mejor loss: 1.0919\n",
      "Modelo guardado: backbone_ssl_best.pth\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = \"C:/Users/JuanTF/Desktop/Gait_Recognition/archive/output\"\n",
    "    \n",
    "if not os.path.exists(ROOT_PATH):\n",
    "    print(f\"ERROR: No existe {ROOT_PATH}\")\n",
    "\n",
    "model = train_ssl(ROOT_PATH, save_path=\"backbone_ssl_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce76aa87",
   "metadata": {},
   "source": [
    "#  Supervised Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7825204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset mode: True\n",
      "Train: 20 sujetos, Val: 10, Test: 10\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = \"C:/Users/JuanTF/Desktop/Gait_Recognition/archive/output\"\n",
    "SSL_CHECKPOINT = \"backbone_ssl_best.pth\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 1e-4  # M√°s bajo que SSL (fine-tuning)\n",
    "MARGIN = 0.3  # Para triplet loss\n",
    "\n",
    "EPOCHS_SUPERVISED = 30\n",
    "EPOCHS_HYBRID = 30\n",
    "\n",
    "# Subset\n",
    "USE_SUBSET = True\n",
    "SUBSET_TRAIN_SUBJECTS = 20  # De 74\n",
    "SUBSET_VAL_SUBJECTS = 10    # De 25\n",
    "SUBSET_TEST_SUBJECTS = 10   # De 25\n",
    "SUBSET_FRAMES_PER_SEQ = 20\n",
    "\n",
    "SUPERVISED_CONFIG = {\n",
    "    'conditions': ['nm-01', 'nm-02'],\n",
    "    'angles': ['090'],\n",
    "    'train_range': (0, SUBSET_TRAIN_SUBJECTS if USE_SUBSET else 74),\n",
    "    'val_range': (74, 74 + SUBSET_VAL_SUBJECTS if USE_SUBSET else 99),\n",
    "    'test_range': (99, 99 + SUBSET_TEST_SUBJECTS if USE_SUBSET else 124),\n",
    "}\n",
    "\n",
    "if not os.path.exists(ROOT_PATH):\n",
    "    raise FileNotFoundError(f\"No existe: {ROOT_PATH}\")\n",
    "\n",
    "print(f\"Subset mode: {USE_SUBSET}\")\n",
    "if USE_SUBSET:\n",
    "    print(f\"Train: {SUBSET_TRAIN_SUBJECTS} sujetos, Val: {SUBSET_VAL_SUBJECTS}, Test: {SUBSET_TEST_SUBJECTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CASIAB_Supervised(Dataset):\n",
    "    def __init__(self, root_path, subject_range, conditions, angles=None, frames_per_seq=20, img_size=(64, 44), augment=False):\n",
    "        self.root = Path(root_path)\n",
    "        self.augment = augment\n",
    "        self.samples = []\n",
    "        self.subject_to_label = {}\n",
    "        \n",
    "        # Obtener person en el rango\n",
    "        all_subjects = sorted([d.name for d in self.root.iterdir() if d.is_dir()])\n",
    "        start_idx, end_idx = subject_range\n",
    "        subjects = all_subjects[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"Sujetos: {start_idx+1:03d}-{end_idx:03d} ({len(subjects)} sujetos)\")\n",
    "        print(f\"Condiciones: {conditions}\")\n",
    "        if angles:\n",
    "            print(f\"√Ångulos: {angles}\")\n",
    "        \n",
    "        # Mapeo id\n",
    "        for label_id, subject_name in enumerate(subjects):\n",
    "            self.subject_to_label[subject_name] = label_id\n",
    "        \n",
    "        # Cargar samples\n",
    "        for subject_name in subjects:\n",
    "            subject_dir = self.root / subject_name\n",
    "            label_id = self.subject_to_label[subject_name]\n",
    "            \n",
    "            for condition_dir in subject_dir.iterdir():\n",
    "                if not condition_dir.is_dir() or condition_dir.name not in conditions:\n",
    "                    continue\n",
    "                \n",
    "                for angle_dir in condition_dir.iterdir():\n",
    "                    if not angle_dir.is_dir():\n",
    "                        continue\n",
    "                    if angles and angle_dir.name not in angles:\n",
    "                        continue\n",
    "                    \n",
    "                    frames = sorted([f for f in angle_dir.iterdir()\n",
    "                                   if f.suffix.lower() in ['.png', '.jpg', '.bmp']])\n",
    "                    \n",
    "                    # Muestreo\n",
    "                    if len(frames) > frames_per_seq:\n",
    "                        step = len(frames) / frames_per_seq\n",
    "                        frames = [frames[int(i * step)] for i in range(frames_per_seq)]\n",
    "                    \n",
    "                    for frame_path in frames:\n",
    "                        self.samples.append({\n",
    "                            'path': frame_path,\n",
    "                            'label': label_id,\n",
    "                            'subject': subject_name,\n",
    "                            'condition': condition_dir.name,\n",
    "                            'angle': angle_dir.name\n",
    "                        })\n",
    "        \n",
    "        print(f\"  Samples: {len(self.samples)}, Clases: {len(self.subject_to_label)}\")\n",
    "        \n",
    "        # Transformaciones\n",
    "        if augment:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(img_size, antialias=True),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.RandomErasing(p=0.3, scale=(0.02, 0.1)),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(img_size, antialias=True),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        img = Image.open(sample['path']).convert(\"L\")\n",
    "        img = self.transform(img)\n",
    "        return img, sample['label']\n",
    "    \n",
    "    def get_num_classes(self):\n",
    "        return len(self.subject_to_label)\n",
    "    \n",
    "    def get_sample_info(self, idx):\n",
    "        \"\"\"Retorna info del sample (√∫til para debugging)\"\"\"\n",
    "        return self.samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6b3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already defined\n",
    "class SSLBackbone(nn.Module):\n",
    "    def __init__(self, embed_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, embed_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.projection(x)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        return z\n",
    "\n",
    "class SupervisedReIDModel(nn.Module):\n",
    "    def __init__(self, backbone, num_classes, freeze_backbone=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            backbone.conv1,\n",
    "            backbone.conv2,\n",
    "            backbone.conv3,\n",
    "            backbone.pool\n",
    "        )\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"  ‚úì Backbone congelado\")\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        features = self.bn(features)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.3):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "    \n",
    "    def forward(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: [B, D] normalizados\n",
    "            labels: [B] IDs de persona\n",
    "        \"\"\"\n",
    "        dist_matrix = torch.cdist(embeddings, embeddings, p=2)\n",
    "        batch_size = embeddings.size(0)\n",
    "        loss = 0.0\n",
    "        num_valid = 0\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            pos_mask = (labels == labels[i]) & (torch.arange(batch_size, device=labels.device) != i)\n",
    "            neg_mask = labels != labels[i]\n",
    "            \n",
    "            if not pos_mask.any() or not neg_mask.any():\n",
    "                continue\n",
    "            \n",
    "            hard_positive = dist_matrix[i][pos_mask].max()\n",
    "            hard_negative = dist_matrix[i][neg_mask].min()\n",
    "            \n",
    "            loss += F.relu(hard_positive - hard_negative + self.margin)\n",
    "            num_valid += 1\n",
    "        \n",
    "        return loss / max(num_valid, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised(save_path=\"supervised_model.pth\"):\n",
    "    print(\"ENTRENAMIENTO SUPERVISADO (CROSSENTROPY)\")\n",
    "    \n",
    "    print(\"TRAIN SET:\")\n",
    "    train_dataset = CASIAB_Supervised(\n",
    "        root_path=ROOT_PATH,\n",
    "        subject_range=SUPERVISED_CONFIG['train_range'],\n",
    "        conditions=SUPERVISED_CONFIG['conditions'],\n",
    "        angles=SUPERVISED_CONFIG['angles'],\n",
    "        frames_per_seq=SUBSET_FRAMES_PER_SEQ if USE_SUBSET else 30,\n",
    "        img_size=IMG_SIZE,\n",
    "        augment=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\nVALIDATION SET:\")\n",
    "    val_dataset = CASIAB_Supervised(\n",
    "        root_path=ROOT_PATH,\n",
    "        subject_range=SUPERVISED_CONFIG['val_range'],\n",
    "        conditions=SUPERVISED_CONFIG['conditions'],\n",
    "        angles=SUPERVISED_CONFIG['angles'],\n",
    "        frames_per_seq=SUBSET_FRAMES_PER_SEQ if USE_SUBSET else 30,\n",
    "        img_size=IMG_SIZE,\n",
    "        augment=False\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    num_classes = train_dataset.get_num_classes()\n",
    "    print(f\"\\nClases (personas) en train: {num_classes}\\n\")\n",
    "    \n",
    "    # Modelo cargando\n",
    "    backbone = SSLBackbone(embed_dim=256)\n",
    "    \n",
    "    if os.path.exists(SSL_CHECKPOINT):\n",
    "        checkpoint = torch.load(SSL_CHECKPOINT, map_location=DEVICE)\n",
    "        backbone.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"  ‚úì Backbone SSL cargado: {SSL_CHECKPOINT}\")\n",
    "        print(f\"    Epoch: {checkpoint['epoch']}, Loss: {checkpoint['loss']:.4f}\")\n",
    "    else:\n",
    "        print(f\"  ‚ö† No se encontr√≥ {SSL_CHECKPOINT}\")\n",
    "        print(f\"    Entrenando desde cero (no recomendado)\")\n",
    "    \n",
    "    model = SupervisedReIDModel(\n",
    "        backbone=backbone,\n",
    "        num_classes=num_classes,\n",
    "        freeze_backbone=False  # Entrenar todo el modelo\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"  Par√°metros entrenables: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\\n\")\n",
    "    \n",
    "    # -------------------------------\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    \n",
    "    print(f\"Configuraci√≥n:\")\n",
    "    print(f\"Epochs: {EPOCHS_SUPERVISED}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"Steps/epoch: {len(train_loader)}\\n\")\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(1, EPOCHS_SUPERVISED + 1):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        \n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                logits = model(images)\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = logits.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        \n",
    "        scheduler.step()\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch:2d}/{EPOCHS_SUPERVISED} | \"\n",
    "              f\"Loss: {train_loss/len(train_loader):.3f} | \"\n",
    "              f\"Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Acc: {val_acc:.2f}% | \"\n",
    "              f\"Time: {epoch_time:.1f}s\")\n",
    "        \n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss / len(val_loader))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'num_classes': num_classes,\n",
    "                'history': history\n",
    "            }, save_path)\n",
    "    \n",
    "    print(f\"ENTRENAMIENTO COMPLETADO\")\n",
    "    print(f\"Mejor Val Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Modelo guardado: {save_path}\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bb94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO SUPERVISADO (CROSSENTROPY)\n",
      "Cargando datasets...\n",
      "\n",
      "TRAIN SET:\n",
      "  Sujetos: 001-020 (20 sujetos)\n",
      "  Condiciones: ['nm-01', 'nm-02']\n",
      "  √Ångulos: ['090']\n",
      "  Samples: 787, Clases: 20\n",
      "\n",
      "VALIDATION SET:\n",
      "  Sujetos: 075-084 (10 sujetos)\n",
      "  Condiciones: ['nm-01', 'nm-02']\n",
      "  √Ångulos: ['090']\n",
      "  Samples: 400, Clases: 10\n",
      "\n",
      "Clases (personas) en train: 20\n",
      "\n",
      "Cargando modelo...\n",
      "\n",
      "  ‚úì Backbone SSL cargado: backbone_ssl_best.pth\n",
      "    Epoch: 10, Loss: 3.0317\n",
      "  Par√°metros entrenables: 281,716 / 281,716 (100.0%)\n",
      "\n",
      "‚öô Configuraci√≥n:\n",
      "  Epochs: 30\n",
      "  Batch size: 32\n",
      "  Learning rate: 0.0001\n",
      "  Steps/epoch: 25\n",
      "\n",
      "Epoch  1/30 | Loss: 2.970 | Train Acc: 9.02% | Val Acc: 1.25% | Time: 1.0s\n",
      "Epoch  2/30 | Loss: 2.743 | Train Acc: 17.66% | Val Acc: 4.50% | Time: 0.9s\n",
      "Epoch  3/30 | Loss: 2.571 | Train Acc: 24.90% | Val Acc: 6.50% | Time: 0.9s\n",
      "Epoch  4/30 | Loss: 2.447 | Train Acc: 29.73% | Val Acc: 3.50% | Time: 0.9s\n",
      "Epoch  5/30 | Loss: 2.306 | Train Acc: 36.09% | Val Acc: 3.25% | Time: 0.8s\n",
      "Epoch  6/30 | Loss: 2.238 | Train Acc: 38.50% | Val Acc: 7.00% | Time: 0.9s\n",
      "Epoch  7/30 | Loss: 2.063 | Train Acc: 44.73% | Val Acc: 4.50% | Time: 0.9s\n",
      "Epoch  8/30 | Loss: 1.964 | Train Acc: 46.12% | Val Acc: 2.00% | Time: 0.9s\n",
      "Epoch  9/30 | Loss: 1.881 | Train Acc: 50.06% | Val Acc: 5.75% | Time: 0.8s\n",
      "Epoch 10/30 | Loss: 1.776 | Train Acc: 54.76% | Val Acc: 2.25% | Time: 0.8s\n",
      "Epoch 11/30 | Loss: 1.682 | Train Acc: 58.20% | Val Acc: 5.00% | Time: 0.9s\n",
      "Epoch 12/30 | Loss: 1.633 | Train Acc: 59.59% | Val Acc: 4.75% | Time: 0.8s\n",
      "Epoch 13/30 | Loss: 1.582 | Train Acc: 60.86% | Val Acc: 4.50% | Time: 0.9s\n",
      "Epoch 14/30 | Loss: 1.529 | Train Acc: 63.28% | Val Acc: 4.50% | Time: 0.9s\n",
      "Epoch 15/30 | Loss: 1.513 | Train Acc: 63.66% | Val Acc: 4.75% | Time: 0.9s\n",
      "Epoch 16/30 | Loss: 1.455 | Train Acc: 67.47% | Val Acc: 4.50% | Time: 0.9s\n",
      "Epoch 17/30 | Loss: 1.472 | Train Acc: 63.66% | Val Acc: 6.50% | Time: 1.0s\n",
      "Epoch 18/30 | Loss: 1.428 | Train Acc: 64.68% | Val Acc: 2.75% | Time: 1.0s\n",
      "Epoch 19/30 | Loss: 1.404 | Train Acc: 66.33% | Val Acc: 6.00% | Time: 0.8s\n",
      "Epoch 20/30 | Loss: 1.362 | Train Acc: 69.76% | Val Acc: 2.75% | Time: 0.8s\n",
      "Epoch 21/30 | Loss: 1.312 | Train Acc: 71.79% | Val Acc: 3.75% | Time: 0.8s\n",
      "Epoch 22/30 | Loss: 1.343 | Train Acc: 68.61% | Val Acc: 4.25% | Time: 0.9s\n",
      "Epoch 23/30 | Loss: 1.266 | Train Acc: 74.21% | Val Acc: 5.75% | Time: 0.9s\n",
      "Epoch 24/30 | Loss: 1.285 | Train Acc: 71.54% | Val Acc: 4.00% | Time: 0.9s\n",
      "Epoch 25/30 | Loss: 1.259 | Train Acc: 71.79% | Val Acc: 6.00% | Time: 0.9s\n",
      "Epoch 26/30 | Loss: 1.276 | Train Acc: 72.68% | Val Acc: 7.50% | Time: 0.9s\n",
      "Epoch 27/30 | Loss: 1.251 | Train Acc: 73.06% | Val Acc: 6.25% | Time: 0.9s\n",
      "Epoch 28/30 | Loss: 1.236 | Train Acc: 72.43% | Val Acc: 4.75% | Time: 0.9s\n",
      "Epoch 29/30 | Loss: 1.219 | Train Acc: 74.59% | Val Acc: 6.50% | Time: 1.0s\n",
      "Epoch 30/30 | Loss: 1.213 | Train Acc: 74.59% | Val Acc: 5.25% | Time: 0.9s\n",
      "\n",
      "======================================================================\n",
      "ENTRENAMIENTO COMPLETADO\n",
      "Mejor Val Accuracy: 7.50%\n",
      "Modelo guardado: supervised_model.pth\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üìä Historial de entrenamiento:\n",
      "  Train Acc final: 74.59%\n",
      "  Val Acc final: 5.25%\n"
     ]
    }
   ],
   "source": [
    "model, history = train_supervised(save_path=\"supervised_model.pth\")\n",
    "    \n",
    "print(\"\\nHistorial de entrenamiento:\")\n",
    "print(f\"Train Acc final: {history['train_acc'][-1]:.2f}%\")\n",
    "print(f\"Val Acc final: {history['val_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd3c19",
   "metadata": {},
   "source": [
    "# Hybrid Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889cec3b",
   "metadata": {},
   "source": [
    "# Evaluaci√≥n y testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProjectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
